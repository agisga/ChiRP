plot(g, layout=coords,vertex.size=5, vertex.label=NA,axes = F, edge.color='gray87',edge.width=1,
vertex.color=col_map[train_clus$class_mem] )
col_map <- c('red','black','green','blue')
names(col_map) <- c('c10','c3', 'c4', 'c6')
par(mfrow=c(1,3))
plot(d$x, d$y, col=col_map[train_clus$class_mem], pch=20)
## plot observed data
plot(d$x, d$y, pch=20, ylim=c(-10,10), xlim=c(min(d$x), 2))
# plot 100 posterior predictive draws on the training set
for(i in 900:1000){
points(d$x, NDP_res$predictions$train[,i], col='gray', pch=20)
points(d_test$x, NDP_res$predictions$test[,i], col='lightgray', pch=20)
}
points(d$x, d$y, pch=20) # overlay data
# plot posterior predictive mean on training.
points(d$x, rowMeans(NDP_res$predictions$train), col='blue', pch=20)
# plot posterior predictive mean on test set.
points(d_test$x, rowMeans(NDP_res$predictions$test), col='red', pch=20)
legend('topleft', legend = c('Training Data','Predictive Draws',
'Predictive Mean (training)','Predictive Mean (test)' ),
col=c('black','gray','blue','red'), pch=c(20,20,20,20))
abline(v=1.73)
g <- graph_from_adjacency_matrix(train_clus$adjmat, diag = F,mode='undirected', weighted=T)
coords <- layout.auto(g)
plot(g, layout=coords,vertex.size=5, vertex.label=NA,axes = F, edge.color='gray87',edge.width=1,
vertex.color=col_map[train_clus$class_mem] )
par(mfrow=c(1,3))
plot(d$x, d$y, col=col_map[train_clus$class_mem], pch=20)
plot(g, layout=coords,vertex.size=5, vertex.label=NA,axes = F,
edge.color='gray87',edge.width=1,
vertex.color=col_map[train_clus$class_mem] )
## plot observed data
plot(d$x, d$y, pch=20, ylim=c(-10,10), xlim=c(min(d$x), 2))
# plot 100 posterior predictive draws on the training set
for(i in 900:1000){
points(d$x, NDP_res$predictions$train[,i], col='gray', pch=20)
points(d_test$x, NDP_res$predictions$test[,i], col='lightgray', pch=20)
}
points(d$x, d$y, pch=20) # overlay data
# plot posterior predictive mean on training.
points(d$x, rowMeans(NDP_res$predictions$train), col='blue', pch=20)
# plot posterior predictive mean on test set.
points(d_test$x, rowMeans(NDP_res$predictions$test), col='red', pch=20)
legend('topleft', legend = c('Training Data','Predictive Draws',
'Predictive Mean (training)','Predictive Mean (test)' ),
col=c('black','gray','blue','red'), pch=c(20,20,20,20))
abline(v=1.73)
g <- graph_from_adjacency_matrix(train_clus$adjmat, diag = F,mode='undirected', weighted=T)
coords <- layout.auto(g)
par(mfrow=c(1,3))
plot(d$x, d$y, col=col_map[train_clus$class_mem], pch=20)
plot(g, layout=coords,vertex.size=5, vertex.label=NA,axes = F,
edge.color='gray87',edge.width=1,
vertex.color=col_map[train_clus$class_mem] )
## plot observed data
plot(d$x, d$y, pch=20, ylim=c(-10,10), xlim=c(min(d$x), 2))
# plot 100 posterior predictive draws on the training set
for(i in 900:1000){
points(d$x, NDP_res$predictions$train[,i], col='gray', pch=20)
points(d_test$x, NDP_res$predictions$test[,i], col='lightgray', pch=20)
}
points(d$x, d$y, pch=20) # overlay data
# plot posterior predictive mean on training.
points(d$x, rowMeans(NDP_res$predictions$train), col='blue', pch=20)
# plot posterior predictive mean on test set.
points(d_test$x, rowMeans(NDP_res$predictions$test), col='red', pch=20)
legend('topleft', legend = c('Training Data','Predictive Draws',
'Predictive Mean (training)','Predictive Mean (test)' ),
col=c('black','gray','blue','red'), pch=c(20,20,20,20))
abline(v=1.73)
g <- graph_from_adjacency_matrix(train_clus$adjmat, diag = F,mode='undirected', weighted=T)
coords <- layout.auto(g)
par(mfrow=c(1,3))
plot(d$x, d$y, col=col_map[train_clus$class_mem], pch=20)
plot(g, layout=coords,vertex.size=5, vertex.label=NA,axes = F,
edge.color='gray87',edge.width=1,
vertex.color=col_map[train_clus$class_mem] )
## plot observed data
plot(d$x, d$y, pch=20, ylim=c(-10,10), xlim=c(min(d$x), 2))
# plot 100 posterior predictive draws on the training set
for(i in 900:1000){
points(d$x, NDP_res$predictions$train[,i], col='gray', pch=20)
points(d_test$x, NDP_res$predictions$test[,i], col='lightgray', pch=20)
}
points(d$x, d$y, pch=20) # overlay data
# plot posterior predictive mean on training.
points(d$x, rowMeans(NDP_res$predictions$train), col='blue', pch=20)
# plot posterior predictive mean on test set.
points(d_test$x, rowMeans(NDP_res$predictions$test), col='red', pch=20)
legend('topleft', legend = c('Training Data','Predictive Draws',
'Predictive Mean (training)','Predictive Mean (test)' ),
col=c('black','gray','blue','red'), pch=c(20,20,20,20))
abline(v=1.73)
g <- graph_from_adjacency_matrix(train_clus$adjmat, diag = F,mode='undirected', weighted=T)
coords <- layout.auto(g)
col_map <- c('red','black','green','blue')
names(col_map) <- c('c10','c3', 'c4', 'c6')
par(mfrow=c(1,3))
plot(d$x, d$y, col=col_map[train_clus$class_mem], pch=20)
plot(g, layout=coords,vertex.size=5, vertex.label=NA,axes = F,
edge.color='gray87',edge.width=1,
vertex.color=col_map[train_clus$class_mem] )
## plot observed data
plot(d$x, d$y, pch=20, ylim=c(-10,10), xlim=c(min(d$x), 2))
# plot 100 posterior predictive draws on the training set
for(i in 900:1000){
points(d$x, NDP_res$predictions$train[,i], col='gray', pch=20)
points(d_test$x, NDP_res$predictions$test[,i], col='lightgray', pch=20)
}
points(d$x, d$y, pch=20) # overlay data
# plot posterior predictive mean on training.
points(d$x, rowMeans(NDP_res$predictions$train), col='blue', pch=20)
# plot posterior predictive mean on test set.
points(d_test$x, rowMeans(NDP_res$predictions$test), col='red', pch=20)
legend('topleft', legend = c('Training Data','Predictive Draws',
'Predictive Mean (training)','Predictive Mean (test)' ),
col=c('black','gray','blue','red'), pch=c(20,20,20,20))
abline(v=1.73)
g <- graph_from_adjacency_matrix(train_clus$adjmat, diag = F,mode='undirected', weighted=T)
coords <- layout.auto(g)
par(mfrow=c(1,3))
plot(d$x, d$y, col=col_map[train_clus$class_mem], pch=20)
plot(g, layout=coords,vertex.size=5, vertex.label=NA,axes = F,
edge.color='gray87',edge.width=1,
vertex.color=col_map[train_clus$class_mem] )
## plot observed data
plot.new()
plot(d$x, d$y, pch=20, ylim=c(-10,10), xlim=c(min(d$x), 2))
# plot 100 posterior predictive draws on the training set
for(i in 900:1000){
points(d$x, NDP_res$predictions$train[,i], col='gray', pch=20)
points(d_test$x, NDP_res$predictions$test[,i], col='lightgray', pch=20)
}
points(d$x, d$y, pch=20) # overlay data
# plot posterior predictive mean on training.
points(d$x, rowMeans(NDP_res$predictions$train), col='blue', pch=20)
# plot posterior predictive mean on test set.
points(d_test$x, rowMeans(NDP_res$predictions$test), col='red', pch=20)
legend('topleft', legend = c('Training Data','Predictive Draws',
'Predictive Mean (training)','Predictive Mean (test)' ),
col=c('black','gray','blue','red'), pch=c(20,20,20,20))
abline(v=1.73)
g <- graph_from_adjacency_matrix(train_clus$adjmat, diag = F,mode='undirected', weighted=T)
coords <- layout.auto(g)
g <- graph_from_adjacency_matrix(train_clus$adjmat, diag = F,mode='undirected', weighted=T)
coords <- layout.auto(g)
par(mfrow=c(1,3))
plot(d$x, d$y, col=col_map[train_clus$class_mem], pch=20)
g <- graph_from_adjacency_matrix(train_clus$adjmat, diag = F,mode='undirected', weighted=T)
coords <- layout.auto(g)
plot(g, layout=coords,vertex.size=5, vertex.label=NA,axes = F,
edge.color='gray87',edge.width=1,
vertex.color=col_map[train_clus$class_mem] )
## plot observed data
plot.new()
plot(d$x, d$y, pch=20, ylim=c(-10,10), xlim=c(min(d$x), 2))
# plot 100 posterior predictive draws on the training set
for(i in 900:1000){
points(d$x, NDP_res$predictions$train[,i], col='gray', pch=20)
points(d_test$x, NDP_res$predictions$test[,i], col='lightgray', pch=20)
}
points(d$x, d$y, pch=20) # overlay data
# plot posterior predictive mean on training.
points(d$x, rowMeans(NDP_res$predictions$train), col='blue', pch=20)
# plot posterior predictive mean on test set.
points(d_test$x, rowMeans(NDP_res$predictions$test), col='red', pch=20)
legend('topleft', legend = c('Training Data','Predictive Draws',
'Predictive Mean (training)','Predictive Mean (test)' ),
col=c('black','gray','blue','red'), pch=c(20,20,20,20))
abline(v=1.73)
par(mfrow=c(1,3))
## plot observed data
plot(d$x, d$y, pch=20, ylim=c(-10,10), xlim=c(min(d$x), 2))
# plot 100 posterior predictive draws on the training set
for(i in 900:1000){
points(d$x, NDP_res$predictions$train[,i], col='gray', pch=20)
points(d_test$x, NDP_res$predictions$test[,i], col='lightgray', pch=20)
}
points(d$x, d$y, pch=20) # overlay data
# plot posterior predictive mean on training.
points(d$x, rowMeans(NDP_res$predictions$train), col='blue', pch=20)
# plot posterior predictive mean on test set.
points(d_test$x, rowMeans(NDP_res$predictions$test), col='red', pch=20)
legend('topleft', legend = c('Training Data','Predictive Draws',
'Predictive Mean (training)','Predictive Mean (test)' ),
col=c('black','gray','blue','red'), pch=c(20,20,20,20))
abline(v=1.73)
plot(d$x, d$y, col=col_map[train_clus$class_mem], pch=20)
g <- graph_from_adjacency_matrix(train_clus$adjmat, diag = F,mode='undirected', weighted=T)
coords <- layout.auto(g)
plot(g, layout=coords,vertex.size=5, vertex.label=NA,axes = F,
edge.color='gray87',edge.width=1,
vertex.color=col_map[train_clus$class_mem] )
par(mfrow=c(1,3))
## plot observed data
plot(d$x, d$y, pch=20, ylim=c(-10,10), xlim=c(min(d$x), 3),
, xlab='X', ylab='Y')
# plot 100 posterior predictive draws on the training set
for(i in 900:1000){
points(d$x, NDP_res$predictions$train[,i], col='gray', pch=20)
points(d_test$x, NDP_res$predictions$test[,i], col='lightgray', pch=20)
}
points(d$x, d$y, pch=20) # overlay data
# plot posterior predictive mean on training.
points(d$x, rowMeans(NDP_res$predictions$train), col='blue', pch=20)
# plot posterior predictive mean on test set.
points(d_test$x, rowMeans(NDP_res$predictions$test), col='red', pch=20)
legend('topleft', legend = c('Training Data','Predictive Draws',
'Predictive Mean (training)','Predictive Mean (test)' ),
col=c('black','gray','blue','red'), pch=c(20,20,20,20))
abline(v=1.73)
plot(d$x, d$y, col=col_map[train_clus$class_mem], pch=20, xlab='X', ylab='Y')
g <- graph_from_adjacency_matrix(train_clus$adjmat, diag = F,mode='undirected', weighted=T)
coords <- layout.auto(g)
plot(g, layout=coords,vertex.size=5, vertex.label=NA,axes = F,
edge.color='gray87',edge.width=1,
vertex.color=col_map[train_clus$class_mem] )
par(mfrow=c(1,3))
## plot observed data
plot(d$x, d$y, pch=20, ylim=c(-10,10), xlim=c(min(d$x), 3),
, xlab='X', ylab='Y')
# plot 100 posterior predictive draws on the training set
for(i in 900:1000){
points(d$x, NDP_res$predictions$train[,i], col='gray', pch=20)
points(d_test$x, NDP_res$predictions$test[,i], col='lightgray', pch=20)
}
points(d$x, d$y, pch=20) # overlay data
# plot posterior predictive mean on training.
points(d$x, rowMeans(NDP_res$predictions$train), col='blue', pch=20)
# plot posterior predictive mean on test set.
points(d_test$x, rowMeans(NDP_res$predictions$test), col='red', pch=20)
legend('topleft', legend = c('Training Data','Predictive Draws',
'Predictive Mean (training)','Predictive Mean (test)' ),
col=c('black','gray','blue','red'), pch=c(20,20,20,20))
abline(v=1.73)
plot(d$x, d$y, col=col_map[train_clus$class_mem], pch=20, xlab='X', ylab='Y')
g <- graph_from_adjacency_matrix(train_clus$adjmat, diag = F,mode='undirected', weighted=T)
coords <- layout.auto(g)
plot(g, layout=coords,vertex.size=5, vertex.label=NA,axes = F,
edge.color='gray87',edge.width=1,
vertex.color=col_map[train_clus$class_mem] )
par(mfrow=c(1,3))
## plot observed data
plot(d$x, d$y, pch=20, ylim=c(-10,10), xlim=c(min(d$x), 3),
, xlab='X', ylab='Y', main='A. Posterior Predictions')
# plot 100 posterior predictive draws on the training set
for(i in 900:1000){
points(d$x, NDP_res$predictions$train[,i], col='gray', pch=20)
points(d_test$x, NDP_res$predictions$test[,i], col='lightgray', pch=20)
}
points(d$x, d$y, pch=20) # overlay data
# plot posterior predictive mean on training.
points(d$x, rowMeans(NDP_res$predictions$train), col='blue', pch=20)
# plot posterior predictive mean on test set.
points(d_test$x, rowMeans(NDP_res$predictions$test), col='red', pch=20)
legend('topleft', legend = c('Training Data','Predictive Draws',
'Predictive Mean (training)','Predictive Mean (test)' ),
col=c('black','gray','blue','red'), pch=c(20,20,20,20))
abline(v=1.73)
plot(d$x, d$y, col=col_map[train_clus$class_mem], pch=20, xlab='X', ylab='Y',
main='B. Posterior Mode Clustering')
g <- graph_from_adjacency_matrix(train_clus$adjmat, diag = F,mode='undirected', weighted=T)
coords <- layout.auto(g)
plot(g, layout=coords,vertex.size=5, vertex.label=NA,
edge.color='gray87',edge.width=1,
vertex.color=col_map[train_clus$class_mem],
main = "Posterior Clustering Probability")
par(mfrow=c(1,3))
## plot observed data
plot(d$x, d$y, pch=20, ylim=c(-10,10), xlim=c(min(d$x), 3),
, xlab='X', ylab='Y', main='A. Posterior Predictions')
# plot 100 posterior predictive draws on the training set
for(i in 900:1000){
points(d$x, NDP_res$predictions$train[,i], col='gray', pch=20)
points(d_test$x, NDP_res$predictions$test[,i], col='lightgray', pch=20)
}
points(d$x, d$y, pch=20) # overlay data
# plot posterior predictive mean on training.
points(d$x, rowMeans(NDP_res$predictions$train), col='blue', pch=20)
# plot posterior predictive mean on test set.
points(d_test$x, rowMeans(NDP_res$predictions$test), col='red', pch=20)
legend('topleft', legend = c('Training Data','Predictive Draws',
'Predictive Mean (training)','Predictive Mean (test)' ),
col=c('black','gray','blue','red'), pch=c(20,20,20,20))
abline(v=1.73)
plot(d$x, d$y, col=col_map[train_clus$class_mem], pch=20, xlab='X', ylab='Y',
main='B. Posterior Mode Clustering')
g <- graph_from_adjacency_matrix(train_clus$adjmat, diag = F,mode='undirected', weighted=T)
coords <- layout.auto(g)
plot(g, layout=coords,vertex.size=5, vertex.label=NA,
edge.color='gray87',edge.width=1,
vertex.color=col_map[train_clus$class_mem],
main = "Posterior Clustering Probability")
par(mfrow=c(1,3))
## plot observed data
plot(d$x, d$y, pch=20, ylim=c(-10,10), xlim=c(min(d$x), 3),
, xlab='X', ylab='Y', main='A. Posterior Predictions')
# plot 100 posterior predictive draws on the training set
for(i in 900:1000){
points(d$x, NDP_res$predictions$train[,i], col='gray', pch=20)
points(d_test$x, NDP_res$predictions$test[,i], col='lightgray', pch=20)
}
points(d$x, d$y, pch=20) # overlay data
# plot posterior predictive mean on training.
points(d$x, rowMeans(NDP_res$predictions$train), col='blue', pch=20)
# plot posterior predictive mean on test set.
points(d_test$x, rowMeans(NDP_res$predictions$test), col='red', pch=20)
legend('topleft', legend = c('Training Data','Predictive Draws',
'Predictive Mean (training)','Predictive Mean (test)' ),
col=c('black','gray','blue','red'), pch=c(20,20,20,20))
abline(v=1.73)
plot(d$x, d$y, col=col_map[train_clus$class_mem], pch=20, xlab='X', ylab='Y',
main='B. Posterior Mode Clustering')
g <- graph_from_adjacency_matrix(train_clus$adjmat, diag = F,mode='undirected', weighted=T)
coords <- layout.auto(g)
plot(g, layout=coords,vertex.size=5, vertex.label=NA,
edge.color='gray87',edge.width=1,axes = T,
vertex.color=col_map[train_clus$class_mem],
main = "Posterior Clustering Probability")
par(mfrow=c(1,3))
## plot observed data
plot(d$x, d$y, pch=20, ylim=c(-10,10), xlim=c(min(d$x), 3),
, xlab='X', ylab='Y', main='A. Posterior Predictions')
# plot 100 posterior predictive draws on the training set
for(i in 900:1000){
points(d$x, NDP_res$predictions$train[,i], col='gray', pch=20)
points(d_test$x, NDP_res$predictions$test[,i], col='lightgray', pch=20)
}
points(d$x, d$y, pch=20) # overlay data
# plot posterior predictive mean on training.
points(d$x, rowMeans(NDP_res$predictions$train), col='blue', pch=20)
# plot posterior predictive mean on test set.
points(d_test$x, rowMeans(NDP_res$predictions$test), col='red', pch=20)
legend('topleft', legend = c('Training Data','Predictive Draws',
'Predictive Mean (training)','Predictive Mean (test)' ),
col=c('black','gray','blue','red'), pch=c(20,20,20,20))
abline(v=1.73)
plot(d$x, d$y, col=col_map[train_clus$class_mem], pch=20, xlab='X', ylab='Y',
main='B. Posterior Mode Clustering')
g <- graph_from_adjacency_matrix(train_clus$adjmat, diag = F,mode='undirected', weighted=T)
coords <- layout.auto(g)
plot(g, layout=coords,vertex.size=5, vertex.label=NA,
edge.color='gray87',edge.width=1,axes = F,
vertex.color=col_map[train_clus$class_mem],
main = "Posterior Clustering Probability")
box()
par(mfrow=c(1,3))
## plot observed data
plot(d$x, d$y, pch=20, ylim=c(-10,10), xlim=c(min(d$x), 3),
, xlab='X', ylab='Y', main='A. Posterior Predictions')
# plot 100 posterior predictive draws on the training set
for(i in 900:1000){
points(d$x, NDP_res$predictions$train[,i], col='gray', pch=20)
points(d_test$x, NDP_res$predictions$test[,i], col='lightgray', pch=20)
}
points(d$x, d$y, pch=20) # overlay data
# plot posterior predictive mean on training.
points(d$x, rowMeans(NDP_res$predictions$train), col='blue', pch=20)
# plot posterior predictive mean on test set.
points(d_test$x, rowMeans(NDP_res$predictions$test), col='red', pch=20)
legend('topleft', legend = c('Training Data','Predictive Draws',
'Predictive Mean (training)','Predictive Mean (test)' ),
col=c('black','gray','blue','red'), pch=c(20,20,20,20))
abline(v=1.73)
plot(d$x, d$y, col=col_map[train_clus$class_mem], pch=20, xlab='X', ylab='Y',
main='B. Posterior Mode Clustering')
g <- graph_from_adjacency_matrix(train_clus$adjmat, diag = F,mode='undirected', weighted=T)
coords <- layout.auto(g)
plot(g, layout=coords,vertex.size=5, vertex.label=NA,
edge.color='gray87',edge.width=1,axes = F,
vertex.color=col_map[train_clus$class_mem],
main = "C. Posterior Clustering Probability")
box()
par(mfrow=c(1,3))
## plot observed data
plot(d$x, d$y, pch=20, ylim=c(-10,10), xlim=c(min(d$x), 3),
, xlab='X', ylab='Y', main='A. Posterior Predictions')
# plot 100 posterior predictive draws on the training set
for(i in 900:1000){
points(d$x, NDP_res$predictions$train[,i], col='gray', pch=20)
points(d_test$x, NDP_res$predictions$test[,i], col='lightgray', pch=20)
}
points(d$x, d$y, pch=20) # overlay data
# plot posterior predictive mean on training.
points(d$x, rowMeans(NDP_res$predictions$train), col='blue', pch=20)
# plot posterior predictive mean on test set.
points(d_test$x, rowMeans(NDP_res$predictions$test), col='red', pch=20)
legend('topleft', legend = c('Training Data','Predictive Draws',
'Predictive Mean (training)','Predictive Mean (test)' ),
col=c('black','gray','blue','red'), pch=c(20,20,20,20))
abline(v=1.73)
plot(d$x, d$y, col=col_map[train_clus$class_mem], pch=20, xlab='X', ylab='Y',
main='B. Posterior Mode Clustering')
g <- graph_from_adjacency_matrix(train_clus$adjmat, diag = F,mode='undirected', weighted=T)
coords <- layout.auto(g)
plot(g, layout=coords,vertex.size=5, vertex.label=NA,
edge.color='gray87',edge.width=1,axes = F,
vertex.color=col_map[train_clus$class_mem],
main = "C. Posterior Clustering Probability")
box()
par(mfrow=c(1,3))
## plot observed data
plot(d$x, d$y, pch=20, ylim=c(-10,10), xlim=c(min(d$x), 3),
, xlab='X', ylab='Y', main='A. Posterior Predictions')
# plot 100 posterior predictive draws on the training set
for(i in 900:1000){
points(d$x, NDP_res$predictions$train[,i], col='gray', pch=20)
points(d_test$x, NDP_res$predictions$test[,i], col='lightgray', pch=20)
}
points(d$x, d$y, pch=20) # overlay data
# plot posterior predictive mean on training.
points(d$x, rowMeans(NDP_res$predictions$train), col='blue', pch=20)
# plot posterior predictive mean on test set.
points(d_test$x, rowMeans(NDP_res$predictions$test), col='red', pch=20)
legend('topleft', legend = c('Training Data','Predictive Draws',
'Predictive Mean (training)','Predictive Mean (test)' ),
col=c('black','gray','blue','red'), pch=c(20,20,20,20))
abline(v=1.73)
plot(d$x, d$y, col=col_map[train_clus$class_mem], pch=20, xlab='X', ylab='Y',
main='B. Posterior Mode Clustering')
g <- graph_from_adjacency_matrix(train_clus$adjmat, diag = F,mode='undirected', weighted=T)
coords <- layout.auto(g)
plot(g, layout=coords,vertex.size=5, vertex.label=NA,
edge.color='gray87',edge.width=1,axes = F,
vertex.color=col_map[train_clus$class_mem],
main = "C. Posterior Clustering Probability")
box()
par(mfrow=c(1,3))
## plot observed data
plot(d$x, d$y, pch=20, ylim=c(-10,10), xlim=c(min(d$x), 3),
, xlab='X', ylab='Y', main='A. Posterior Predictions')
# plot 100 posterior predictive draws on the training set
for(i in 900:1000){
points(d$x, NDP_res$predictions$train[,i], col='gray', pch=20)
points(d_test$x, NDP_res$predictions$test[,i], col='lightgray', pch=20)
}
points(d$x, d$y, pch=20) # overlay data
# plot posterior predictive mean on training.
points(d$x, rowMeans(NDP_res$predictions$train), col='blue', pch=20)
# plot posterior predictive mean on test set.
points(d_test$x, rowMeans(NDP_res$predictions$test), col='red', pch=20)
legend('topleft', legend = c('Training Data','Predictive Draws',
'Predictive Mean (training)','Predictive Mean (test)' ),
col=c('black','gray','blue','red'), pch=c(20,20,20,20))
abline(v=1.73)
plot(d$x, d$y, col=col_map[train_clus$class_mem], pch=20, xlab='X', ylab='Y',
main='B. Posterior Mode Clustering')
g <- graph_from_adjacency_matrix(train_clus$adjmat, diag = F,mode='undirected', weighted=T)
coords <- layout.auto(g)
plot(g, layout=coords,vertex.size=5, vertex.label=NA,
edge.color='gray87',edge.width=1,axes = F,
vertex.color=col_map[train_clus$class_mem],
main = "C. Posterior Clustering Probability")
box()
par(mfrow=c(1,3))
## plot observed data
plot(d$x, d$y, pch=20, ylim=c(-10,10), xlim=c(min(d$x), 3),
, xlab='X', ylab='Y', main='A. Posterior Predictions')
# plot 100 posterior predictive draws on the training set
for(i in 900:1000){
points(d$x, NDP_res$predictions$train[,i], col='gray', pch=20)
points(d_test$x, NDP_res$predictions$test[,i], col='lightgray', pch=20)
}
points(d$x, d$y, pch=20) # overlay data
# plot posterior predictive mean on training.
points(d$x, rowMeans(NDP_res$predictions$train), col='blue', pch=20)
# plot posterior predictive mean on test set.
points(d_test$x, rowMeans(NDP_res$predictions$test), col='red', pch=20)
legend('topleft', legend = c('Training Data','Predictive Draws',
'Predictive Mean (training)','Predictive Mean (test)' ),
col=c('black','gray','blue','red'), pch=c(20,20,20,20))
abline(v=1.73)
plot(d$x, d$y, col=col_map[train_clus$class_mem], pch=20, xlab='X', ylab='Y',
main='B. Posterior Mode Clustering')
g <- graph_from_adjacency_matrix(train_clus$adjmat, diag = F,mode='undirected', weighted=T)
coords <- layout.auto(g)
plot(g, layout=coords,vertex.size=5, vertex.label=NA,
edge.color='gray87',edge.width=1,axes = F,
vertex.color=col_map[train_clus$class_mem],
main = "C. Posterior Clustering Probability")
box()
par(mfrow=c(1,3))
## plot observed data
plot(d$x, d$y, pch=20, ylim=c(-10,10), xlim=c(min(d$x), 3),
, xlab='X', ylab='Y', main='A. Posterior Predictions')
# plot 100 posterior predictive draws on the training set
for(i in 900:1000){
points(d$x, NDP_res$predictions$train[,i], col='gray', pch=20)
points(d_test$x, NDP_res$predictions$test[,i], col='lightgray', pch=20)
}
points(d$x, d$y, pch=20) # overlay data
# plot posterior predictive mean on training.
points(d$x, rowMeans(NDP_res$predictions$train), col='blue', pch=20)
# plot posterior predictive mean on test set.
points(d_test$x, rowMeans(NDP_res$predictions$test), col='red', pch=20)
legend('topleft', legend = c('Training Data','Predictive Draws',
'Predictive Mean (training)','Predictive Mean (test)' ),
col=c('black','gray','blue','red'), pch=c(20,20,20,20))
abline(v=1.73)
plot(d$x, d$y, col=col_map[train_clus$class_mem], pch=20, xlab='X', ylab='Y',
main='B. Posterior Mode Clustering')
g <- graph_from_adjacency_matrix(train_clus$adjmat, diag = F,mode='undirected', weighted=T)
coords <- layout.auto(g)
plot(g, layout=coords,vertex.size=5, vertex.label=NA,
edge.color='gray87',edge.width=1,axes = F,
vertex.color=col_map[train_clus$class_mem],
main = "C. Posterior Clustering Probability")
box()
getwd()
?ChiRP::NDPMix
?ChiRP::ZDPMix
?ChiRP::PDPMix
